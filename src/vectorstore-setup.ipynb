{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":22796,"sourceType":"datasetVersion","datasetId":17368,"isSourceIdPinned":false}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Book Recommender\nPurpose: to explore topics in Information Retrieval and RAG.","metadata":{}},{"cell_type":"markdown","source":"## Environment Setup","metadata":{}},{"cell_type":"code","source":"%%capture\n\n# installations\n!pip install --quiet sentence_transformers transformers torch peft huggingface_hub kaggle pinecone lark rank_bm25 langchain_huggingface langdetect langchain_experimental \n\n# THE REGS\nimport pandas as pd\nimport numpy as np\nimport kagglehub\nimport torch\nimport nltk\nimport string\nimport os\nimport time\nimport re\n\n# NLP\nimport nltk\nfrom langdetect import detect, DetectorFactory\n\n# Transformers\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\n\n# PINECONE\nfrom pinecone import Pinecone\nfrom pinecone import ServerlessSpec\n\n# LANGCHAIN\nfrom langchain_huggingface import HuggingFaceEmbeddings\n\n# Kaggle environment\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:45:31.366338Z","iopub.execute_input":"2025-08-18T18:45:31.366649Z","iopub.status.idle":"2025-08-18T18:47:55.799727Z","shell.execute_reply.started":"2025-08-18T18:45:31.366619Z","shell.execute_reply":"2025-08-18T18:47:55.798703Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Data Setup","metadata":{}},{"cell_type":"code","source":"# Reformat data file so it fits into a pandas dataframe\ndef text_to_csv_pandas(input_file, output_file, column_names, delimiter=None):\n    \"\"\"\n    Reads a text file into a Pandas DataFrame and saves it as a CSV file.\n\n    Args:\n        input_file (str): The path to the input text file.\n        output_file (str): The path to the output CSV file.\n        delimiter (str, optional): The delimiter used in the text file. Defaults to None, \n        which will split each line by whitespace if the text file is not delimited.\n    \"\"\"\n    if delimiter is not None:\n        df = pd.read_csv(input_file, sep=delimiter, names = column_names, header=None)\n    else:\n         df = pd.read_csv(input_file, sep=r'\\s+', names = column_names, header=None)\n    df.to_csv(output_file, index=False, header=True)\n\n# Columns in the data set\ncolumns = ['Wikipedia article ID', \n           'Freebase ID', \n           'Book title', \n           'Author', \n           'Publication date', \n           'Book genres', \n           'Plot summary']\n\ntext_to_csv_pandas('/kaggle/input/cmu-book-summary-dataset/booksummaries.txt', 'data.csv', \n                   column_names = columns, delimiter='\\t')\n\ndata = pd.read_csv('/kaggle/working/data.csv')\n\n# drop the ID columns\ndata.drop(columns=['Wikipedia article ID', 'Freebase ID'], inplace=True)\n\n# preview\ndata.head(n=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:47:55.802225Z","iopub.execute_input":"2025-08-18T18:47:55.802832Z","iopub.status.idle":"2025-08-18T18:47:59.330702Z","shell.execute_reply.started":"2025-08-18T18:47:55.802788Z","shell.execute_reply":"2025-08-18T18:47:59.329728Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"           Book title           Author Publication date  \\\n0         Animal Farm    George Orwell       1945-08-17   \n1  A Clockwork Orange  Anthony Burgess             1962   \n2          The Plague     Albert Camus             1947   \n\n                                         Book genres  \\\n0  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n1  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n2  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n\n                                        Plot summary  \n0   Old Major, the old boar on the Manor Farm, ca...  \n1   Alex, a teenager living in near-future Englan...  \n2   The text of The Plague is divided into five p...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Book title</th>\n      <th>Author</th>\n      <th>Publication date</th>\n      <th>Book genres</th>\n      <th>Plot summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Animal Farm</td>\n      <td>George Orwell</td>\n      <td>1945-08-17</td>\n      <td>{\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...</td>\n      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A Clockwork Orange</td>\n      <td>Anthony Burgess</td>\n      <td>1962</td>\n      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...</td>\n      <td>Alex, a teenager living in near-future Englan...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Plague</td>\n      <td>Albert Camus</td>\n      <td>1947</td>\n      <td>{\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...</td>\n      <td>The text of The Plague is divided into five p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"code","source":"print(\"Number of NA values for each feature:\\n\", data.isna().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:47:59.332122Z","iopub.execute_input":"2025-08-18T18:47:59.332974Z","iopub.status.idle":"2025-08-18T18:47:59.349047Z","shell.execute_reply.started":"2025-08-18T18:47:59.332945Z","shell.execute_reply":"2025-08-18T18:47:59.347855Z"}},"outputs":[{"name":"stdout","text":"Number of NA values for each feature:\n Book title             0\nAuthor              2382\nPublication date    5610\nBook genres         3718\nPlot summary           0\ndtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Genre Column\n* Remove brackets\n* Remove /m/ char sequences\n* Fix utf-8 symbols\n* Put genres in list format for each cell","metadata":{}},{"cell_type":"code","source":"# CLEAN GENRE COLUMN\n\n# Find all genres in cell block, do not keep char sequences that begin with /m/\ndata['Book genres'] = data['Book genres'].apply(lambda row: re.findall(r'\":\\s*\"([^\"]+)\"', str(row)))\n\n# take care of utf-8 symbols as well (ex. \\\\u00e0)\ndata['Book genres'] = data['Book genres'].apply(lambda cell: [bytes(word, \"utf-8\").decode(\"unicode_escape\") for word in cell])\n\n# Preview\ndata.head(n=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:47:59.351043Z","iopub.execute_input":"2025-08-18T18:47:59.351471Z","iopub.status.idle":"2025-08-18T18:47:59.452372Z","shell.execute_reply.started":"2025-08-18T18:47:59.351432Z","shell.execute_reply":"2025-08-18T18:47:59.451153Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"           Book title           Author Publication date  \\\n0         Animal Farm    George Orwell       1945-08-17   \n1  A Clockwork Orange  Anthony Burgess             1962   \n2          The Plague     Albert Camus             1947   \n\n                                         Book genres  \\\n0  [Roman à clef, Satire, Children's literature, ...   \n1  [Science Fiction, Novella, Speculative fiction...   \n2  [Existentialism, Fiction, Absurdist fiction, N...   \n\n                                        Plot summary  \n0   Old Major, the old boar on the Manor Farm, ca...  \n1   Alex, a teenager living in near-future Englan...  \n2   The text of The Plague is divided into five p...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Book title</th>\n      <th>Author</th>\n      <th>Publication date</th>\n      <th>Book genres</th>\n      <th>Plot summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Animal Farm</td>\n      <td>George Orwell</td>\n      <td>1945-08-17</td>\n      <td>[Roman à clef, Satire, Children's literature, ...</td>\n      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A Clockwork Orange</td>\n      <td>Anthony Burgess</td>\n      <td>1962</td>\n      <td>[Science Fiction, Novella, Speculative fiction...</td>\n      <td>Alex, a teenager living in near-future Englan...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Plague</td>\n      <td>Albert Camus</td>\n      <td>1947</td>\n      <td>[Existentialism, Fiction, Absurdist fiction, N...</td>\n      <td>The text of The Plague is divided into five p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"### Publication date column\n* The majority of the books half the publication year, therefore we will create a new column for it.","metadata":{}},{"cell_type":"code","source":"# regex to find dates that only contain the year\nregex = r'\\d{4}$'\nyear_only_dates = data[data['Publication date'].str.contains(regex) == True].index\nprint(\"Number of books with only the publication year: \", len(year_only_dates))\n\n# regex to find dates that only contain year and month\nregex = r'\\d{4}-\\d{2}$'\nhalf_dates = data[data['Publication date'].str.contains(regex) == True].index\nprint(\"Number of books with just the year and month: \", len(half_dates))\n\n# regex to find complete dates\nregex = r'\\d{4}-\\d{2}-\\d{2}'\nfull_dates = data[data['Publication date'].str.contains(regex) == True].index\nprint(\"Number of books with the full publication date: \", len(full_dates))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:47:59.453741Z","iopub.execute_input":"2025-08-18T18:47:59.454136Z","iopub.status.idle":"2025-08-18T18:47:59.503280Z","shell.execute_reply.started":"2025-08-18T18:47:59.454108Z","shell.execute_reply":"2025-08-18T18:47:59.502104Z"}},"outputs":[{"name":"stdout","text":"Number of books with only the publication year:  6799\nNumber of books with just the year and month:  1479\nNumber of books with the full publication date:  2671\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# CREATE NEW COLUMN FOR PUBLICATION YEAR\n\n# New column for publication year\ndata['Publication year'] = 0\n\n# Fill in column with year values\ndata.loc[full_dates, 'Publication year'] = data.loc[full_dates, 'Publication date'].str.split(\"-\").str[0].astype('int')\ndata.loc[half_dates, 'Publication year'] = data.loc[half_dates, 'Publication date'].str.split(\"-\").str[0].astype('int')\ndata.loc[year_only_dates, 'Publication year'] = data.loc[year_only_dates, 'Publication date'].str.split(\"-\").str[0].astype('int')\n\n# Preview\ndata.head(n=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:47:59.504341Z","iopub.execute_input":"2025-08-18T18:47:59.505248Z","iopub.status.idle":"2025-08-18T18:48:00.273008Z","shell.execute_reply.started":"2025-08-18T18:47:59.505219Z","shell.execute_reply":"2025-08-18T18:48:00.272055Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           Book title           Author Publication date  \\\n0         Animal Farm    George Orwell       1945-08-17   \n1  A Clockwork Orange  Anthony Burgess             1962   \n2          The Plague     Albert Camus             1947   \n\n                                         Book genres  \\\n0  [Roman à clef, Satire, Children's literature, ...   \n1  [Science Fiction, Novella, Speculative fiction...   \n2  [Existentialism, Fiction, Absurdist fiction, N...   \n\n                                        Plot summary  Publication year  \n0   Old Major, the old boar on the Manor Farm, ca...              1945  \n1   Alex, a teenager living in near-future Englan...              1962  \n2   The text of The Plague is divided into five p...              1947  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Book title</th>\n      <th>Author</th>\n      <th>Publication date</th>\n      <th>Book genres</th>\n      <th>Plot summary</th>\n      <th>Publication year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Animal Farm</td>\n      <td>George Orwell</td>\n      <td>1945-08-17</td>\n      <td>[Roman à clef, Satire, Children's literature, ...</td>\n      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n      <td>1945</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A Clockwork Orange</td>\n      <td>Anthony Burgess</td>\n      <td>1962</td>\n      <td>[Science Fiction, Novella, Speculative fiction...</td>\n      <td>Alex, a teenager living in near-future Englan...</td>\n      <td>1962</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Plague</td>\n      <td>Albert Camus</td>\n      <td>1947</td>\n      <td>[Existentialism, Fiction, Absurdist fiction, N...</td>\n      <td>The text of The Plague is divided into five p...</td>\n      <td>1947</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### Plot summary column\n* Remove books with no proper description of the plot.","metadata":{}},{"cell_type":"code","source":"# get number of words per plot summary\nwords_per_summary = data['Plot summary'].apply(lambda x: len(nltk.word_tokenize(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:48:00.274246Z","iopub.execute_input":"2025-08-18T18:48:00.274845Z","iopub.status.idle":"2025-08-18T18:48:42.818050Z","shell.execute_reply.started":"2025-08-18T18:48:00.274811Z","shell.execute_reply":"2025-08-18T18:48:42.816921Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"data.loc[words_per_summary[words_per_summary < 10].index].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:48:42.820675Z","iopub.execute_input":"2025-08-18T18:48:42.821018Z","iopub.status.idle":"2025-08-18T18:48:42.835975Z","shell.execute_reply.started":"2025-08-18T18:48:42.820991Z","shell.execute_reply":"2025-08-18T18:48:42.834943Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                               Book title          Author Publication date  \\\n2045               The Kennel Murder Case  S. S. Van Dine              NaN   \n3879                              Slavers    Chris Pramas             2000   \n5271                   Golem in the Gears   Piers Anthony          1986-02   \n5595  The Adventures of Super Diaper Baby      Dav Pilkey             2002   \n5693                The Deathlord of Ixia      John Grant             1992   \n\n                                            Book genres  \\\n2045                       [Mystery, Fiction, Suspense]   \n3879                                [Role-playing game]   \n5271  [Science Fiction, Speculative fiction, Fantasy...   \n5595                            [Children's literature]   \n5693  [Gamebook, Speculative fiction, Children's lit...   \n\n                    Plot summary  Publication year  \n2045   ~Plot outline description                 0  \n3879        ==Publication histor              2000  \n5271          pl:Zakochany golem              1986  \n5595        === Plot summary ===              2002  \n5693                  ==Receptio              1992  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Book title</th>\n      <th>Author</th>\n      <th>Publication date</th>\n      <th>Book genres</th>\n      <th>Plot summary</th>\n      <th>Publication year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2045</th>\n      <td>The Kennel Murder Case</td>\n      <td>S. S. Van Dine</td>\n      <td>NaN</td>\n      <td>[Mystery, Fiction, Suspense]</td>\n      <td>~Plot outline description</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3879</th>\n      <td>Slavers</td>\n      <td>Chris Pramas</td>\n      <td>2000</td>\n      <td>[Role-playing game]</td>\n      <td>==Publication histor</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>5271</th>\n      <td>Golem in the Gears</td>\n      <td>Piers Anthony</td>\n      <td>1986-02</td>\n      <td>[Science Fiction, Speculative fiction, Fantasy...</td>\n      <td>pl:Zakochany golem</td>\n      <td>1986</td>\n    </tr>\n    <tr>\n      <th>5595</th>\n      <td>The Adventures of Super Diaper Baby</td>\n      <td>Dav Pilkey</td>\n      <td>2002</td>\n      <td>[Children's literature]</td>\n      <td>=== Plot summary ===</td>\n      <td>2002</td>\n    </tr>\n    <tr>\n      <th>5693</th>\n      <td>The Deathlord of Ixia</td>\n      <td>John Grant</td>\n      <td>1992</td>\n      <td>[Gamebook, Speculative fiction, Children's lit...</td>\n      <td>==Receptio</td>\n      <td>1992</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Regex pattern (e.g., any row containing 'apple' or 'grape')\npattern = r'=='\n\n# Find matching indices\ndata[data['Plot summary'].str.contains(pattern, regex=True)].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:48:42.836993Z","iopub.execute_input":"2025-08-18T18:48:42.837867Z","iopub.status.idle":"2025-08-18T18:48:42.914573Z","shell.execute_reply.started":"2025-08-18T18:48:42.837840Z","shell.execute_reply":"2025-08-18T18:48:42.913661Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"               Book title               Author Publication date  \\\n281             Excession           Iain Banks             1996   \n373            The Prince  Niccolò Machiavelli             1532   \n1024  Oahspe: A New Bible                  NaN             1882   \n1497  Three Men in a Boat     Jerome K. Jerome             1889   \n1550               Area 7       Matthew Reilly       2001-10-31   \n\n                                 Book genres  \\\n281   [Science Fiction, Speculative fiction]   \n373                  [Treatise, Non-fiction]   \n1024                              [Religion]   \n1497        [Children's literature, Fiction]   \n1550              [Techno-thriller, Fiction]   \n\n                                           Plot summary  Publication year  \n281    The Excession of the title is a perfect black...              1996  \n373    The work has a recognizable structure, for th...              1532  \n1024   Oahspe includes doctrinal books, and precepts...              1882  \n1497   ==Reception and history== The reception by cr...              1889  \n1550   The President of the United States is visitin...              2001  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Book title</th>\n      <th>Author</th>\n      <th>Publication date</th>\n      <th>Book genres</th>\n      <th>Plot summary</th>\n      <th>Publication year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>281</th>\n      <td>Excession</td>\n      <td>Iain Banks</td>\n      <td>1996</td>\n      <td>[Science Fiction, Speculative fiction]</td>\n      <td>The Excession of the title is a perfect black...</td>\n      <td>1996</td>\n    </tr>\n    <tr>\n      <th>373</th>\n      <td>The Prince</td>\n      <td>Niccolò Machiavelli</td>\n      <td>1532</td>\n      <td>[Treatise, Non-fiction]</td>\n      <td>The work has a recognizable structure, for th...</td>\n      <td>1532</td>\n    </tr>\n    <tr>\n      <th>1024</th>\n      <td>Oahspe: A New Bible</td>\n      <td>NaN</td>\n      <td>1882</td>\n      <td>[Religion]</td>\n      <td>Oahspe includes doctrinal books, and precepts...</td>\n      <td>1882</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <td>Three Men in a Boat</td>\n      <td>Jerome K. Jerome</td>\n      <td>1889</td>\n      <td>[Children's literature, Fiction]</td>\n      <td>==Reception and history== The reception by cr...</td>\n      <td>1889</td>\n    </tr>\n    <tr>\n      <th>1550</th>\n      <td>Area 7</td>\n      <td>Matthew Reilly</td>\n      <td>2001-10-31</td>\n      <td>[Techno-thriller, Fiction]</td>\n      <td>The President of the United States is visitin...</td>\n      <td>2001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### Since there are multiple valid plot summaries that have 2+ equal signs, we will need to remove them.","metadata":{}},{"cell_type":"code","source":"# Replace substrings with 2+ equal signs\ndata['Plot summary'] = data['Plot summary'].str.replace(r'={2,}', '', regex=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:48:42.915371Z","iopub.execute_input":"2025-08-18T18:48:42.915676Z","iopub.status.idle":"2025-08-18T18:48:43.534464Z","shell.execute_reply.started":"2025-08-18T18:48:42.915655Z","shell.execute_reply":"2025-08-18T18:48:43.533169Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# drop rows that have 5 terms or less\ndata.drop(words_per_summary[words_per_summary < 6].index.tolist(), inplace=True)\n\n# drop rows that contain \"Plot outline description\" \ndata.drop(data[data['Plot summary'].str.contains(pattern, regex=True)].index.tolist(), inplace=True)\n\n# dropping rows does not automatically reset index. So we must do this manually.\ndata.reset_index(drop=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:48:43.535775Z","iopub.execute_input":"2025-08-18T18:48:43.536133Z","iopub.status.idle":"2025-08-18T18:48:43.600432Z","shell.execute_reply.started":"2025-08-18T18:48:43.536106Z","shell.execute_reply":"2025-08-18T18:48:43.599458Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# DELETE BOOKS THAT ARE NOT IN ENGLISH\nDetectorFactory.seed = 0  # for consistent results\n\ndef detect_language(text):\n    try:\n        lang = detect(text)\n        return lang\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\nlangs = data['Plot summary'].apply(lambda x: detect_language(x))\neng_books = langs[langs == 'en'].index\n\nprint(\"Number of english summaries in dataset: \", len(eng_books))\n\ndata = data.loc[eng_books]\ndata.reset_index(drop=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:48:43.601697Z","iopub.execute_input":"2025-08-18T18:48:43.602430Z","iopub.status.idle":"2025-08-18T18:50:38.893581Z","shell.execute_reply.started":"2025-08-18T18:48:43.602370Z","shell.execute_reply":"2025-08-18T18:50:38.892244Z"}},"outputs":[{"name":"stdout","text":"Number of english summaries in dataset:  16512\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Check to see if there are any other common things that do not add to the summary that I should remove (for embeddings)\ndata['Plot summary'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:50:38.894789Z","iopub.execute_input":"2025-08-18T18:50:38.895094Z","iopub.status.idle":"2025-08-18T18:50:38.901353Z","shell.execute_reply.started":"2025-08-18T18:50:38.895071Z","shell.execute_reply":"2025-08-18T18:50:38.900456Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"' Old Major, the old boar on the Manor Farm, calls the animals on the farm for a meeting, where he compares the humans to parasites and teaches the animals a revolutionary song, \\'Beasts of England\\'. When Major dies, two young pigs, Snowball and Napoleon, assume command and turn his dream into a philosophy. The animals revolt and drive the drunken and irresponsible Mr Jones from the farm, renaming it \"Animal Farm\". They adopt Seven Commandments of Animal-ism, the most important of which is, \"All animals are equal\". Snowball attempts to teach the animals reading and writing; food is plentiful, and the farm runs smoothly. The pigs elevate themselves to positions of leadership and set aside special food items, ostensibly for their personal health. Napoleon takes the pups from the farm dogs and trains them privately. Napoleon and Snowball struggle for leadership. When Snowball announces his plans to build a windmill, Napoleon has his dogs chase Snowball away and declares himself leader. Napoleon enacts changes to the governance structure of the farm, replacing meetings with a committee of pigs, who will run the farm. Using a young pig named Squealer as a \"mouthpiece\", Napoleon claims credit for the windmill idea. The animals work harder with the promise of easier lives with the windmill. After a violent storm, the animals find the windmill annihilated. Napoleon and Squealer convince the animals that Snowball destroyed it, although the scorn of the neighbouring farmers suggests that its walls were too thin. Once Snowball becomes a scapegoat, Napoleon begins purging the farm with his dogs, killing animals he accuses of consorting with his old rival. He and the pigs abuse their power, imposing more control while reserving privileges for themselves and rewriting history, villainising Snowball and glorifying Napoleon. Squealer justifies every statement Napoleon makes, even the pigs\\' alteration of the Seven Commandments of Animalism to benefit themselves. \\'Beasts of England\\' is replaced by an anthem glorifying Napoleon, who appears to be adopting the lifestyle of a man. The animals remain convinced that they are better off than they were when under Mr Jones. Squealer abuses the animals\\' poor memories and invents numbers to show their improvement. Mr Frederick, one of the neighbouring farmers, attacks the farm, using blasting powder to blow up the restored windmill. Though the animals win the battle, they do so at great cost, as many, including Boxer the workhorse, are wounded. Despite his injuries, Boxer continues working harder and harder, until he collapses while working on the windmill. Napoleon sends for a van to take Boxer to the veterinary surgeon\\'s, explaining that better care can be given there. Benjamin, the cynical donkey, who \"could read as well as any pig\", notices that the van belongs to a knacker, and attempts to mount a rescue; but the animals\\' attempts are futile. Squealer reports that the van was purchased by the hospital and the writing from the previous owner had not been repainted. He recounts a tale of Boxer\\'s death in the hands of the best medical care. Years pass, and the pigs learn to walk upright, carry whips and wear clothes. The Seven Commandments are reduced to a single phrase: \"All animals are equal, but some animals are more equal than others\". Napoleon holds a dinner party for the pigs and the humans of the area, who congratulate Napoleon on having the hardest-working but least fed animals in the country. Napoleon announces an alliance with the humans, against the labouring classes of both \"worlds\". He abolishes practices and traditions related to the Revolution, and changes the name of the farm to \"The Manor Farm\". The animals, overhearing the conversation, notice that the faces of the pigs have begun changing. During a poker match, an argument breaks out between Napoleon and Mr Pilkington, and the animals realise that the faces of the pigs look like the faces of humans, and no one can tell the difference between them. The pigs Snowball, Napoleon, and Squealer adapt Old Major\\'s ideas into an actual philosophy, which they formally name Animalism. Soon after, Napoleon and Squealer indulge in the vices of humans (drinking alcohol, sleeping in beds, trading). Squealer is employed to alter the Seven Commandments to account for this humanisation, an allusion to the Soviet government\\'s revising of history in order to exercise control of the people\\'s beliefs about themselves and their society. The original commandments are: # Whatever goes upon two legs is an enemy. # Whatever goes upon four legs, or has wings, is a friend. # No animal shall wear clothes. # No animal shall sleep in a bed. # No animal shall drink alcohol. # No animal shall kill any other animal. # All animals are equal. Later, Napoleon and his pigs secretly revise some commandments to clear them of accusations of law-breaking (such as \"No animal shall drink alcohol\" having \"to excess\" appended to it and \"No animal shall sleep in a bed\" with \"with sheets\" added to it). The changed commandments are as follows, with the changes bolded: * 4 No animal shall sleep in a bed with sheets. * 5 No animal shall drink alcohol to excess. * 6 No animal shall kill any other animal without cause. Eventually these are replaced with the maxims, \"All animals are equal, but some animals are more equal than others\", and \"Four legs good, two legs better!\" as the pigs become more human. This is an ironic twist to the original purpose of the Seven Commandments, which were supposed to keep order within Animal Farm by uniting the animals together against the humans, and prevent animals from following the humans\\' evil habits. Through the revision of the commandments, Orwell demonstrates how simply political dogma can be turned into malleable propaganda.'"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"data['Plot summary'] = data['Plot summary'].apply(lambda x: x.replace('#', ''))\ndata['Plot summary'] = data['Plot summary'].apply(lambda x: x.replace('*', ''))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:50:38.902320Z","iopub.execute_input":"2025-08-18T18:50:38.902727Z","iopub.status.idle":"2025-08-18T18:50:38.994784Z","shell.execute_reply.started":"2025-08-18T18:50:38.902696Z","shell.execute_reply":"2025-08-18T18:50:38.993791Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### Note:\n* Stopwords are not removed as part of the text cleaning process because we are using an LLM to embed-- which are already trained with stopwords and therefore handle the importance of them internally.","metadata":{}},{"cell_type":"markdown","source":"## Preparing Data for Database","metadata":{}},{"cell_type":"markdown","source":"### Step 1: Determine which embedding model we will use. \n* We will use BAAI's tuned BERT model.","metadata":{}},{"cell_type":"code","source":"# Get model\nmodel_name = \"BAAI/bge-large-zh-v1.5\"\nmodel = AutoModel.from_pretrained(model_name)\n\nprint(\"About the model: \\n\\n\", model.eval(), \"\\n\")\n\n# Get corresponding tokenizer/encoder\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nprint(\"About the tokenizer: \\n\\n\", tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:52:11.180512Z","iopub.execute_input":"2025-08-18T18:52:11.180867Z","iopub.status.idle":"2025-08-18T18:52:45.467696Z","shell.execute_reply.started":"2025-08-18T18:52:11.180842Z","shell.execute_reply":"2025-08-18T18:52:45.466297Z"}},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77d645495e5f41e3a85627a5ee8dd89e"}},"metadata":{}},{"name":"stderr","text":"2025-08-18 18:52:19.282735: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755543139.580452      90 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755543139.667211      90 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.30G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea7cf0d776884baabb1746e1e7405691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.30G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be0758d2f2eb47aea1a8f142f4167fba"}},"metadata":{}},{"name":"stdout","text":"About the model: \n\n BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(21128, 1024, padding_idx=0)\n    (position_embeddings): Embedding(512, 1024)\n    (token_type_embeddings): Embedding(2, 1024)\n    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-23): 24 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSdpaSelfAttention(\n            (query): Linear(in_features=1024, out_features=1024, bias=True)\n            (key): Linear(in_features=1024, out_features=1024, bias=True)\n            (value): Linear(in_features=1024, out_features=1024, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (activation): Tanh()\n  )\n) \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ab82bd02eba4c5c9c9971f3aea08fb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4eab55e9854a1292a825485a530df8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15dbe5c1f0e8446cba99ce98232de08e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0d01be599c34494b66234dfe5acc474"}},"metadata":{}},{"name":"stdout","text":"About the tokenizer: \n\n BertTokenizerFast(name_or_path='BAAI/bge-large-zh-v1.5', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}\n)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Additional Configuration details\nmodel.config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:59:18.360528Z","iopub.execute_input":"2025-08-18T18:59:18.363338Z","iopub.status.idle":"2025-08-18T18:59:18.376127Z","shell.execute_reply.started":"2025-08-18T18:59:18.363248Z","shell.execute_reply":"2025-08-18T18:59:18.375146Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"BertConfig {\n  \"_attn_implementation_autoset\": true,\n  \"architectures\": [\n    \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.51.3\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 21128\n}"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"### Step 2: Create LangChain Documents","metadata":{}},{"cell_type":"markdown","source":"#### 1.1 Create a text splitter\nWhy: because embeddings can lose information when input text is too large. \n[[5]](https://python.langchain.com/docs/concepts/text_splitters/)\n\nIf you have good computational power, try: LangChain's semantic chunker \n\n\n> **Breakpoints**\n>\n> This chunker works by determining when to \"break\" apart sentences. This is done by looking for differences in embeddings between any two sentences. When that difference is past some threshold, then they are split.\n>\n> There are a few ways to determine what that threshold is, which are controlled by the breakpoint_threshold_type kwarg.\n>\n> Note: if the resulting chunk sizes are too small/big, the additional kwargs breakpoint_threshold_amount and min_chunk_size can be used for adjustments.\n>\n> **Percentile**\n>\n> The default way to split is based on percentile. In this method, all differences between sentences are calculated, and then any difference greater than the X percentile is split. The default value for X is 95.0 and can be adjusted by the keyword argument breakpoint_threshold_amount which expects a number between 0.0 and 100.0.\n>\n> [[6]](https://python.langchain.com/docs/how_to/semantic-chunker/)\n\n**Eco-friendly option: The character text splitter**\n\n\n> Text-structured based\n>\n> Text is naturally organized into hierarchical units such as paragraphs, sentences, and words. We can leverage this inherent structure to inform our splitting strategy, creating split that maintain natural language flow, maintain semantic coherence within split, and adapts to varying levels of text granularity. LangChain's RecursiveCharacterTextSplitter implements this concept:\n> The RecursiveCharacterTextSplitter attempts to keep larger units (e.g., paragraphs) intact.\n> If a unit exceeds the chunk size, it moves to the next level (e.g., sentences).\n> This process continues down to the word level if necessary.\n>\n> [[7]](https://python.langchain.com/docs/concepts/text_splitters/)\n\n\n**More about Document object in Langchain:** https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html","metadata":{}},{"cell_type":"markdown","source":"### Issue: LangChain does not support BERT tokenizers. \n* We must create a custom text splitter.","metadata":{}},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerBase\nfrom langchain.text_splitter import TextSplitter\nfrom typing import List\n\n\nclass CustomTokenTextSplitter(TextSplitter):\n    def __init__(\n        self,\n        tokenizer: PreTrainedTokenizerBase,\n        chunk_size: int = 512,\n        chunk_overlap: int = 50,\n    ):\n        super().__init__(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n        self.tokenizer = tokenizer\n\n    def split_text(self, text: str) -> List[str]:\n        # Tokenize the input text (no special tokens)\n        input_ids = self.tokenizer.encode(text, add_special_tokens=False)\n\n        chunks = []\n        i = 0\n        while i < len(input_ids):\n            end = i + self.chunk_size\n            chunk_ids = input_ids[i:end]\n            chunk_text = self.tokenizer.decode(chunk_ids, skip_special_tokens=True)\n            chunks.append(chunk_text)\n            i += self.chunk_size - self.chunk_overlap\n\n        return chunks\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T19:30:53.060122Z","iopub.execute_input":"2025-08-18T19:30:53.060834Z","iopub.status.idle":"2025-08-18T19:30:53.071244Z","shell.execute_reply.started":"2025-08-18T19:30:53.060807Z","shell.execute_reply":"2025-08-18T19:30:53.069823Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# create text splitter object using BAAI BGE's token input size.\ntext_splitter = TokenTextSplitter(\n    'BertTokenizer', chunk_size=model.config.max_position_embeddings, chunk_overlap=50\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T19:22:06.661812Z","iopub.execute_input":"2025-08-18T19:22:06.662192Z","iopub.status.idle":"2025-08-18T19:22:06.698525Z","shell.execute_reply.started":"2025-08-18T19:22:06.662165Z","shell.execute_reply":"2025-08-18T19:22:06.697308Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_90/3109585622.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create text splitter object using BAAI BGE's token input size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m text_splitter = TokenTextSplitter(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'BertTokenizer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_position_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_overlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_text_splitters/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, encoding_name, model_name, allowed_special, disallowed_special, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiktoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiktoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allowed_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallowed_special\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tiktoken/registry.py\u001b[0m in \u001b[0;36mget_encoding\u001b[0;34m(encoding_name)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mENCODING_CONSTRUCTORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0;34mf\"Unknown encoding {encoding_name}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;34mf\"Plugins found: {_available_plugin_modules()}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unknown encoding BertTokenizer.\nPlugins found: ['tiktoken_ext.openai_public']\ntiktoken version: 0.9.0 (are you on latest?)"],"ename":"ValueError","evalue":"Unknown encoding BertTokenizer.\nPlugins found: ['tiktoken_ext.openai_public']\ntiktoken version: 0.9.0 (are you on latest?)","output_type":"error"}],"execution_count":31},{"cell_type":"markdown","source":"### Step 3: Set up embedder\n#### How Embeddings Operate\nModel: https://huggingface.co/BAAI/bge-m3\n\n**Encoding**:\n* This is a broad term that refers to the process of transforming data from one format to another. Examples include converting text into binary format, converting characters to numerical values, or compressing data. [[1]](https://medium.com/@pratiyush1/understanding-different-types-of-encoding-and-decoding-in-programming-with-practical-examples-dcbdd5215605#:~:text=Practical%20Example%201:%20Email%20Attachments%20Base64%20encoding,were%20traditionally%20designed%20to%20handle%20text%2Donly%20data)\n  \n**Tokenization**:\n* In the context of natural language processing (NLP), tokenization is a specific type of encoding where text is broken down into smaller units called tokens. These tokens can be words, characters, or even sub-word units. [[2]](https://www.datacamp.com/blog/what-is-tokenization#:~:text=Training%20more%20people?,which%20are%20easier%20to%20analyze)\n\n**Embeddings**:\n* are advanced vector representations of tokens. They try to capture the most nuance, connections, and semantic meanings between tokens. Each embedding is generally a series of real numbers on a vector space computed by a neural network. [[3]](https://medium.com/the-research-nest/explained-tokens-and-embeddings-in-llms-69a16ba5db33)\n\n\n> In short, text is converted to tokens. Tokens are assigned token IDs. These token IDs can be used to create embeddings for more nuanced numerical representation in complex models.\n>\n> Why are embeddings so large and complex? What do they signify?\n>\n> Each token’s embedding is a high-dimensional vector. This allows the model to capture a wide range of linguistic features and nuances, like the meaning of a word, its part of speech, and its relationship to other words in the sentence.\n>\n> * Contextual Embeddings: Unlike simpler word embeddings (like Word2Vec), BERT’s embeddings are contextual. This means the same word can have different embeddings based on its context (its surrounding words). The embeddings need to be rich and complex to capture this contextual nuance.\n> \n> * In more complex models like BERT, you get the final embeddings and access to the embeddings from each layer of the neural network. Each layer captures different aspects of the language, adding to the complexity and size of the tensor.\n>\n> * Input for Further Tasks: These embeddings are used as input for various NLP tasks like sentiment analysis, question answering, and language translation. The richness of the embeddings allows the model to perform these tasks with a high degree of sophistication.\n>\n> * Model’s Internal Representation: The complexity of these tensors reflects how the model ‘understands’ language. Each dimension in the embedding can represent some abstract language feature the model learned during its training.\n> [[3]](https://medium.com/the-research-nest/explained-tokens-and-embeddings-in-llms-69a16ba5db33)","metadata":{}},{"cell_type":"code","source":"# need to use a huggingface model wrapper when pairing it with Langchain\nembeddings_model = HuggingFaceEmbeddings(model_name=model_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenizing example\ntest = tokenizer(\"This is a test\")\ntest","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T14:27:10.719821Z","iopub.execute_input":"2025-08-14T14:27:10.721355Z","iopub.status.idle":"2025-08-14T14:27:10.731281Z","shell.execute_reply.started":"2025-08-14T14:27:10.721318Z","shell.execute_reply":"2025-08-14T14:27:10.730209Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 3: Create an embedding function using the LLM","metadata":{}},{"cell_type":"code","source":"model_kwargs = {'device': 'cpu'}\n#encode_kwargs = {'normalize_embeddings': True} # normalization not needed since we are chunking the text into equal parts.\nembedder = HuggingFaceEmbeddings(\n    model_name=model_name,\n    model_kwargs=model_kwargs,\n    #encode_kwargs=encode_kwargs\n)\nprint(embedder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T14:34:10.923804Z","iopub.execute_input":"2025-08-14T14:34:10.924870Z","iopub.status.idle":"2025-08-14T14:34:17.145196Z","shell.execute_reply.started":"2025-08-14T14:34:10.924830Z","shell.execute_reply":"2025-08-14T14:34:17.144245Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Vectorstore Setup","metadata":{}},{"cell_type":"code","source":"# setting up pinecone env (index created in Pinecone)\npc = Pinecone(api_key=user_secrets.get_secret(\"PINECONE_API_KEY\"))\nindex_name = \"recommend-me-vector-store\"\nindex = pc.Index(index_name)\n\nprint(\"Index statistics:\\n\\n\", index.describe_index_stats())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Populate the Vectorstore\n* Using our LangChain Documents, the embedder function, and our Pinecone index, we can populate the vector store with our book data.","metadata":{}},{"cell_type":"code","source":"# Create Main Namespace\n\n# add vectors to pinecone using embed function\ndb = PineconeVectorStore.from_documents(documents=splits,\n                                        embedding=embedder, # note: embedder also handles tokenizing so we do not need a separate process\n                                        index_name=index_name,\n                                        namespace=\"main\"\n                                        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import openai\nimport pinecone\nfrom sentence_transformers import SentenceTransformer\nimport os\n\n# Set up API keys\nopenai.api_key = \"your-openai-api-key\"\npinecone.init(api_key=\"your-pinecone-api-key\", environment=\"us-west1-gcp\")\n\n# Initialize the Sentence-Transformer model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')  # You can use any pre-trained model\n\n# Connect to your Pinecone index (replace with your actual index name)\nindex_name = \"document-index\"\nindex = pinecone.Index(index_name)\n\n# Sample documents (you can replace this with loading documents from files or other sources)\ndocuments = [\n    {\"id\": \"1\", \"text\": \"Python is an amazing programming language.\"},\n    {\"id\": \"2\", \"text\": \"Pinecone is a vector database for similarity search.\"},\n    {\"id\": \"3\", \"text\": \"Embedding models transform text into numeric vectors.\"}\n]\n\n# Process and embed documents\ndef embed_documents(documents):\n    # List to store the embeddings and metadata to add to Pinecone\n    vectors = []\n    \n    for doc in documents:\n        # Create an embedding for the document\n        embedding = model.encode(doc[\"text\"]).tolist()  # Convert to list for Pinecone compatibility\n        # Add embedding and metadata to vectors\n        vectors.append({\n            'id': doc['id'],         # Document ID\n            'values': embedding,     # The embedding vector\n            'metadata': {'text': doc['text']}  # Optional metadata (e.g., the original text)\n        })\n    \n    return vectors\n\n# Add embeddings to Pinecone\ndef add_to_pinecone(vectors):\n    index.upsert(vectors)  # Upload vectors to Pinecone\n\n# Main process\ndef process_and_upload_documents():\n    vectors = embed_documents(documents)\n    add_to_pinecone(vectors)\n    print(\"Documents have been embedded and added to Pinecone.\")\n\n# Run the process\nprocess_and_upload_documents()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Test the retreival operation\n(We will need this later.)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}